{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7115f08",
   "metadata": {},
   "source": [
    "# Input Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc45a1",
   "metadata": {},
   "source": [
    "#### import Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1abf36e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a56a8a2",
   "metadata": {},
   "source": [
    "## CHANGE PATH FOR YOU MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a5a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the files\n",
    "# gift_card_path = 'Sentiment-analysis-with-LLM/raw_data/amazon_reviews_us_Gift_Card_v1_00.tsv'\n",
    "# major_appliances_path = 'Sentiment-analysis-with-LLM/raw_data/amazon_reviews_us_Major_Appliances_v1_00.tsv'\n",
    "\n",
    "gift_card_path = 'raw_data/amazon_reviews_us_Gift_Card_v1_00.tsv'\n",
    "major_appliances_path = 'raw_data/amazon_reviews_us_Major_Appliances_v1_00.tsv'\n",
    "apparel_path = 'raw_data/amazon_reviews_us_Apparel_v1_00.tsv'\n",
    "beauty_path = 'raw_data/amazon_reviews_us_Beauty_v1_00.tsv'\n",
    "shoes_path = 'raw_data/amazon_reviews_us_Shoes_v1_00.tsv'\n",
    "\n",
    "# Read the files into dataframes\n",
    "df_gift_card = pd.read_csv(gift_card_path, sep='\\t', error_bad_lines=False)\n",
    "df_major_appliances = pd.read_csv(major_appliances_path, sep='\\t', error_bad_lines=False)\n",
    "df_apparel = pd.read_csv(apparel_path, sep='\\t', error_bad_lines=False)\n",
    "df_beauty = pd.read_csv(beauty_path, sep='\\t', error_bad_lines=False)\n",
    "df_shoes = pd.read_csv(shoes_path, sep='\\t', error_bad_lines=False)\n",
    "\n",
    "# Display the first few rows of each dataframe to verify\n",
    "print(\"Gift Card Reviews DataFrame:\")\n",
    "display(df_gift_card.head(1))\n",
    "print(\"\\nMajor Appliances Reviews DataFrame:\")\n",
    "display(df_major_appliances.head(1))\n",
    "print(\"Apparel Reviews DataFrame:\")\n",
    "display(df_apparel.head(1))\n",
    "print(\"Beauty Reviews DataFrame:\")\n",
    "display(df_beauty.head(1))\n",
    "print(\"Shoes Reviews DataFrame:\")\n",
    "display(df_shoes.head(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f829c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beauty = pd.read_csv(beauty_path, sep='\\t', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cb156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_beauty.columns)\n",
    "print(df_beauty.shape)\n",
    "df_beauty.info()\n",
    "df_beauty.star_rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2625c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select a product category: 'Gift Card', 'Major Appliances','Apparel','Beauty','Shoes' or 'all'\n",
      "Your choice: Shoes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/r5l1t4656pbc6bzdv94m9wrm0000gn/T/ipykernel_80782/1195340520.py:18: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  return pd.read_csv(dataset_path, sep='\\t', error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/3h/r5l1t4656pbc6bzdv94m9wrm0000gn/T/ipykernel_80782/1195340520.py:18: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  return pd.read_csv(dataset_path, sep='\\t', error_bad_lines=False, warn_bad_lines=True)\n",
      "Skipping line 54101: expected 15 fields, saw 22\n",
      "Skipping line 55857: expected 15 fields, saw 22\n",
      "Skipping line 60448: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 76918: expected 15 fields, saw 22\n",
      "Skipping line 87925: expected 15 fields, saw 22\n",
      "Skipping line 88500: expected 15 fields, saw 22\n",
      "Skipping line 114276: expected 15 fields, saw 22\n",
      "Skipping line 128751: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 136095: expected 15 fields, saw 22\n",
      "Skipping line 140007: expected 15 fields, saw 22\n",
      "Skipping line 177148: expected 15 fields, saw 22\n",
      "Skipping line 180087: expected 15 fields, saw 22\n",
      "Skipping line 183010: expected 15 fields, saw 22\n",
      "Skipping line 183949: expected 15 fields, saw 22\n",
      "Skipping line 192879: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 223261: expected 15 fields, saw 22\n",
      "Skipping line 240588: expected 15 fields, saw 22\n",
      "Skipping line 247955: expected 15 fields, saw 22\n",
      "Skipping line 249336: expected 15 fields, saw 22\n",
      "Skipping line 259363: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 265664: expected 15 fields, saw 22\n",
      "Skipping line 277141: expected 15 fields, saw 22\n",
      "Skipping line 297657: expected 15 fields, saw 22\n",
      "Skipping line 301661: expected 15 fields, saw 22\n",
      "Skipping line 309377: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 344785: expected 15 fields, saw 22\n",
      "Skipping line 373123: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 437625: expected 15 fields, saw 22\n",
      "Skipping line 439026: expected 15 fields, saw 22\n",
      "Skipping line 453540: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 459450: expected 15 fields, saw 22\n",
      "Skipping line 468663: expected 15 fields, saw 22\n",
      "Skipping line 482395: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 541205: expected 15 fields, saw 22\n",
      "Skipping line 552195: expected 15 fields, saw 22\n",
      "Skipping line 556974: expected 15 fields, saw 22\n",
      "Skipping line 574056: expected 15 fields, saw 22\n",
      "Skipping line 582215: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 605428: expected 15 fields, saw 22\n",
      "Skipping line 607292: expected 15 fields, saw 22\n",
      "Skipping line 609689: expected 15 fields, saw 22\n",
      "Skipping line 642724: expected 15 fields, saw 22\n",
      "Skipping line 643401: expected 15 fields, saw 22\n",
      "Skipping line 644251: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 666488: expected 15 fields, saw 22\n",
      "Skipping line 706286: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 734419: expected 15 fields, saw 22\n",
      "Skipping line 735910: expected 15 fields, saw 22\n",
      "Skipping line 744996: expected 15 fields, saw 22\n",
      "Skipping line 750340: expected 15 fields, saw 22\n",
      "Skipping line 768733: expected 15 fields, saw 22\n",
      "Skipping line 774206: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 792985: expected 15 fields, saw 22\n",
      "Skipping line 832430: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 873437: expected 15 fields, saw 22\n",
      "Skipping line 881702: expected 15 fields, saw 22\n",
      "Skipping line 883194: expected 15 fields, saw 22\n",
      "Skipping line 895053: expected 15 fields, saw 22\n",
      "Skipping line 917189: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 920384: expected 15 fields, saw 22\n",
      "Skipping line 926024: expected 15 fields, saw 22\n",
      "Skipping line 937160: expected 15 fields, saw 22\n",
      "Skipping line 949530: expected 15 fields, saw 22\n",
      "Skipping line 965534: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 994267: expected 15 fields, saw 22\n",
      "Skipping line 1001768: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1060583: expected 15 fields, saw 22\n",
      "Skipping line 1076464: expected 15 fields, saw 22\n",
      "Skipping line 1090206: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1123320: expected 15 fields, saw 22\n",
      "Skipping line 1134620: expected 15 fields, saw 22\n",
      "Skipping line 1161774: expected 15 fields, saw 22\n",
      "Skipping line 1173906: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1226184: expected 15 fields, saw 22\n",
      "Skipping line 1227345: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1299308: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1314885: expected 15 fields, saw 22\n",
      "Skipping line 1319270: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1400785: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1452664: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1553197: expected 15 fields, saw 22\n",
      "Skipping line 1565603: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1581194: expected 15 fields, saw 22\n",
      "Skipping line 1588532: expected 15 fields, saw 22\n",
      "Skipping line 1593760: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1638506: expected 15 fields, saw 22\n",
      "Skipping line 1684480: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1751648: expected 15 fields, saw 22\n",
      "Skipping line 1754239: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1813371: expected 15 fields, saw 22\n",
      "Skipping line 1833867: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1843271: expected 15 fields, saw 22\n",
      "Skipping line 1878226: expected 15 fields, saw 22\n",
      "Skipping line 1878565: expected 15 fields, saw 22\n",
      "Skipping line 1879284: expected 15 fields, saw 22\n",
      "Skipping line 1879583: expected 15 fields, saw 22\n",
      "Skipping line 1879619: expected 15 fields, saw 22\n",
      "Skipping line 1880224: expected 15 fields, saw 22\n",
      "Skipping line 1881528: expected 15 fields, saw 22\n",
      "Skipping line 1883001: expected 15 fields, saw 22\n",
      "Skipping line 1897746: expected 15 fields, saw 22\n",
      "Skipping line 1900482: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1937218: expected 15 fields, saw 22\n",
      "Skipping line 1947384: expected 15 fields, saw 22\n",
      "Skipping line 1950536: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1974526: expected 15 fields, saw 22\n",
      "Skipping line 1999157: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 2049158: expected 15 fields, saw 22\n",
      "Skipping line 2059966: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 2136949: expected 15 fields, saw 22\n",
      "Skipping line 2139761: expected 15 fields, saw 22\n",
      "Skipping line 2159242: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 2172137: expected 15 fields, saw 22\n",
      "Skipping line 2225127: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 2242683: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 2324179: expected 15 fields, saw 22\n",
      "Skipping line 2350637: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 2369709: expected 15 fields, saw 22\n",
      "Skipping line 2374408: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 3001832: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 3250530: expected 15 fields, saw 22\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for 'Shoes' category loaded.\n",
      "Available variables: marketplace, product_title, product_category, star_rating, helpful_votes, total_votes, verified_purchase, review_headline, review_body, review_date\n",
      "Enter the variables you're interested in, separated by commas (e.g., marketplace, product_title): star_rating, verified_purchase\n",
      "Unique values for star_rating: 1, 5, 4, 3, 2\n",
      "Enter the values you're interested in for star_rating, separated by commas (leave blank to skip): 5\n",
      "Unique values for verified_purchase: Y, N\n",
      "Enter the values you're interested in for verified_purchase, separated by commas (leave blank to skip): Y\n",
      "Selected filters: {'star_rating': ['5'], 'verified_purchase': ['Y']}\n",
      "Filtered dataset based on your selections.\n",
      "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
      "1          US     16251825  R12VVR0WH5Q24V  B00CFYZH5W       259035853   \n",
      "\n",
      "                 product_title product_category  star_rating  helpful_votes  \\\n",
      "1  Teva Men's Pajaro Flip-Flop            Shoes            5              0   \n",
      "\n",
      "   total_votes vine verified_purchase  review_headline  \\\n",
      "1            0    N                 Y  super flip flop   \n",
      "\n",
      "                                     review_body review_date  \n",
      "1  provides great cushion as well as archsupport  2015-08-31  \n"
     ]
    }
   ],
   "source": [
    "# Define the file paths for the datasets\n",
    "\n",
    "#gift_card_path = 'raw_data/amazon_reviews_us_Gift_Card_v1_00.tsv'\n",
    "#major_appliances_path = 'raw_data/amazon_reviews_us_Major_Appliances_v1_00.tsv'\n",
    "\n",
    "gift_card_path = 'raw_data/amazon_reviews_us_Gift_Card_v1_00.tsv'\n",
    "major_appliances_path = 'raw_data/amazon_reviews_us_Major_Appliances_v1_00.tsv'\n",
    "apparel_path = 'raw_data/amazon_reviews_us_Apparel_v1_00.tsv'\n",
    "beauty_path = 'raw_data/amazon_reviews_us_Beauty_v1_00.tsv'\n",
    "shoes_path = 'raw_data/amazon_reviews_us_Shoes_v1_00.tsv'\n",
    "\n",
    "\n",
    "# Function to read a specific dataset\n",
    "# def read_dataset(dataset_path):\n",
    "#     return pd.read_csv(dataset_path, sep='\\t', error_bad_lines=False)\n",
    "\n",
    "def read_dataset(dataset_path):\n",
    "    return pd.read_csv(dataset_path, sep='\\t', error_bad_lines=False, warn_bad_lines=True)\n",
    "\n",
    "\n",
    "# def read_dataset(dataset_path):\n",
    "#     return pd.read_csv(\n",
    "#         dataset_path, \n",
    "#         sep='\\t', \n",
    "#         error_bad_lines=False, \n",
    "#         warn_bad_lines=True, \n",
    "#         quoting=csv.QUOTE_MINIMAL,  # Or csv.QUOTE_ALL if every field is quoted\n",
    "#         escapechar='\\\\'  # Assumes backslash is used as escape character\n",
    "#     )\n",
    "\n",
    "\n",
    "\n",
    "# Function to merge datasets based on user selection\n",
    "def merge_datasets(selected_category):\n",
    "    if selected_category == 'Gift Card':\n",
    "        return read_dataset(gift_card_path)\n",
    "    elif selected_category == 'Major Appliances':\n",
    "        return read_dataset(major_appliances_path)\n",
    "    elif selected_category == 'Apparel':\n",
    "        return read_dataset(apparel_path)\n",
    "    elif selected_category == 'Beauty':\n",
    "        return read_dataset(beauty_path)\n",
    "    elif selected_category == 'Shoes':\n",
    "        return read_dataset(shoes_path) \n",
    "    elif selected_category == 'all':\n",
    "        df_gift_card = read_dataset(gift_card_path)\n",
    "        df_major_appliances = read_dataset(major_appliances_path)\n",
    "        return pd.concat([df_gift_card, df_major_appliances], ignore_index=True)\n",
    "\n",
    "# Function to filter the dataset based on selected filters\n",
    "def filter_dataset(df, filters):\n",
    "    for variable, selected_values in filters.items():\n",
    "        if variable in ['star_rating', 'total_votes']:  # Convert to integer for numeric filtering\n",
    "            df = df[df[variable].astype(int).isin([int(value) for value in selected_values])]\n",
    "        else:  # For strings, use the values as-is\n",
    "            df = df[df[variable].isin(selected_values)]\n",
    "    return df\n",
    "\n",
    "# Ask user for the product category they're interested in\n",
    "def get_user_category_selection():\n",
    "    print(\"Please select a product category: 'Gift Card', 'Major Appliances','Apparel','Beauty','Shoes' or 'all'\")\n",
    "    category = input(\"Your choice: \").strip()\n",
    "    # Default to \"all\" if the input is empty or not in the expected options\n",
    "    if category not in ['Gift Card', 'Major Appliances','Apparel' ,'Beauty', 'Shoes','all']:\n",
    "        print(\"Invalid selection. Defaulting to 'all'.\")\n",
    "        category = 'all'\n",
    "    elif category == '':\n",
    "        category = 'all'\n",
    "    return category\n",
    "\n",
    "# Ask user for their variable selections\n",
    "def get_user_variable_selections():\n",
    "    print(\"Available variables: marketplace, product_title, product_category, star_rating, helpful_votes, total_votes, verified_purchase, review_headline, review_body, review_date\")\n",
    "    selections = input(\"Enter the variables you're interested in, separated by commas (e.g., marketplace, product_title): \").strip()\n",
    "    \n",
    "    # List of all available variables\n",
    "    all_variables = ['marketplace', 'product_title', 'product_category', 'star_rating', 'helpful_votes', 'total_votes', 'verified_purchase', 'review_headline', 'review_body', 'review_date']\n",
    "    \n",
    "    # If the user provides no input, default to all variables without further prompting for details\n",
    "    if selections == '':\n",
    "        return []\n",
    "    \n",
    "    selected_variables = [var.strip() for var in selections.split(',')]\n",
    "    \n",
    "    return selected_variables\n",
    "\n",
    "# Display unique values for selected variables and collect user choices\n",
    "def display_and_select_unique_values(df, selected_variables):\n",
    "    # If no variables were selected (indicating the user pressed enter without selection),\n",
    "    # skip prompting for details and return an empty filter set.\n",
    "    if not selected_variables:\n",
    "        return {}\n",
    "    \n",
    "    filters = {}\n",
    "    for variable in selected_variables:\n",
    "        unique_values = df[variable].dropna().unique()\n",
    "        print(f\"Unique values for {variable}: {', '.join(unique_values.astype(str))}\")\n",
    "        selected_values = input(f\"Enter the values you're interested in for {variable}, separated by commas (leave blank to skip): \")\n",
    "        if selected_values:\n",
    "            filters[variable] = [value.strip() for value in selected_values.split(',')]\n",
    "    return filters\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    selected_category = get_user_category_selection()\n",
    "    df = merge_datasets(selected_category)\n",
    "    print(f\"Dataset for '{selected_category}' category loaded.\")\n",
    "\n",
    "    selected_variables = get_user_variable_selections()\n",
    "    # Skip prompting for details if no variables were selected\n",
    "    if selected_variables:\n",
    "        filters = display_and_select_unique_values(df, selected_variables)\n",
    "        print(f\"Selected filters: {filters}\")\n",
    "\n",
    "        # Apply the filters to the dataset\n",
    "        filtered_df = filter_dataset(df, filters)\n",
    "        print(\"Filtered dataset based on your selections.\")\n",
    "        print(filtered_df.head(1))\n",
    "    else:\n",
    "        print(\"No variable selections made. Displaying first entries of the dataset.\")\n",
    "        print(df.head(1))\n",
    "    # Display or process the filtered_df as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f46333d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee876131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
